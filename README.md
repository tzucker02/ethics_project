# Introduction
For the most part, there do not seem to be specific policies aimed at English Language Learners (ELL) and how instructors of those students should use AI detectors (other than the generic rule that AI detectors should not be the sole determinant of AI‑generated work) (Dang & Wang 2024; Najarro 2023).

Several institutions have policy examples for the use of generative AI by students (BU 2023; CELT 2025; Cornell 2023; Palmer‑Clarke 2025; Vanderbilt 2023). Those policies do not specifically address ELL/ESL students.

# POLICY
Many academic institutions currently advise instructors NOT to use AI detectors (Berman 2025; Coley 2023; MIT Sloan 2023; Teaching Center doesn’t endorse any generative AI detection tools 2023; Vanderbilt 2023) because of the high number of false positives they have experienced.

Most provide general guidelines on student AI use and offer templates for creating AI‑usage or detector policies for each class (“Academic Integrity,” 2025; Cornell 2023). While this approach has been the best so far at addressing most legal concerns—including civil‑rights issues—it has not addressed the problem directly.

Civil‑rights issues arise because a false positive that disproportionately affects ELLs could invoke Title IV of the Civil Rights Act (disparate treatment, disparate impact, hostile learning environment). The Office of Civil Rights warned in November 2024 that inappropriate use of AI detectors could trigger an OCR investigation (Riess 2025).

AI detection systems may incorrectly flag student‑created writing as AI‑generated under certain conditions. Such false positives can harm the academic record and emotional well‑being of a student, especially non‑native English speakers (Najarro 2023), neurodivergent students, and ESL students. Schools should treat detectors as a starting point for discussion rather than definitive proof.

“GenAI detection tools privilege students who are English first language, have access to paid large‑language models/applications, and are more digitally literate.” (Furze 2024)

Approaching this from a purely ethical point of view, a character‑based ethical framework asks whether it is right to use a tool that inherently discriminates against a particular group (here, ELL).

The very basis for using AI detectors—to ensure integrity of written work and help students achieve their best—paradoxically increases the risk of misidentifying ELL‑generated human text as AI‑generated. The resulting false positive can be disastrous: the student must defend work they have already done rather than focus on improvement.

Therefore, in a pure ethical/logical sense, AI detectors should not be used alone when evaluating ELL students’ writing (Academic Integrity 2025; Cornell 2023; Dang & Wang 2024; MIT Sloan 2023; Teaching Center doesn’t endorse any generative AI detection tools 2023).

A way to address this directly is to enact an optional, top‑down policy for instructors of ELL.

# Why use AI‑detectors at all?
Generally, AI‑detectors, when used with ELL students, cause more problems than they fix (Check 2025; Giray 2024; Teaching Center doesn’t endorse any generative AI detection tools 2023; “Why AI Detection Tools are Ineffective | Center for Academic Innovation,” 2025). Since evidence shows that AI detectors identify more ELL students’ writing as false positives than native‑speaker writing (Mathewson 2023; Myers 2023), it is ethically prudent to use such tools only in extreme cases. Instructors should follow basic principles: baseline sampling (Cambridge 2025; Kratzer 2020), initial review scanning (“Assessing Student Writing,” 2025), and inform students in advance about GenAI and AI‑detection policies.

If AI detectors are deemed useful, instructors should follow guidelines for selecting tools with the lowest likelihood of false positives (Mahmood 2023).

## Guidelines for use
Cost – How much does the detector cost? Free trials? Limits on text length?
Accuracy – Reported accuracy (company vs. third‑party) and whether accuracy holds for ELL work.
What’s included – Does it bundle a plagiarism checker? An AI “humanizer”?
Integration – Browser plug‑in, API access, integration with LLMs?
Batch – Batch‑upload feature to save time.
Extreme caution should be taken if AI detectors are used (Employability‑Survey‑Report 2024). Instructors should consult the updated Bloom’s taxonomy (Jones 2025). A detection score should be only one of many findings used to determine AI assistance.

# Enforcement
Institutions can enforce requirements through:

Faculty hearings, honor codes (faculty + students)
AI usage boards to adjudicate accusations
Requiring students to adhere to academic‑integrity policies (“Code of Academic Integrity,” 2025)
Failure to follow can lead to severe penalties, including expulsion and, for international students, possible visa loss.

Legal concerns when AI detectors are not employed
Even when detectors are not used, AI‑generated text may contain errors (Bohannon 2023; Marcus 2022; Weaver 2023a,b). Students with access to tools can correct hallucinations, while ELL students lacking access may fall behind. AI tools tend to favor native speakers with higher income (Furze 2024), widening inequities.

Supporting evidence: Stanford study (Myers 2023; Tian 2023; Woelfel et al. 2023) showed that non‑native writers are significantly over‑represented among false positives. Of 91 TOEFL essays, 61 % were incorrectly flagged; all seven detectors misclassified 19 % of essays; at least one detector flagged 97 % of TOEFL essays.

Other sources (Hirsch 2024; Mathewson 2023) confirm heightened anxiety, stigma, and administrative burden for ELL writers flagged falsely.

Alternative technical solutions (Pangram Labs 2025; Tian 2023) and policy actions (Vanderbilt disabling Turnitin’s AI detector) exist, but their accuracy and feasibility remain open questions.

# Safeguards
Because of the above risks, institutions should implement safeguards:

- Manual review of any AI‑detector flag on ELL work
- Transparent appeals process
- Increased educator awareness

Using AI detectors voluntarily without a policy may cause unforeseen problems. A 2024 Center for Democracy & Technology survey found 68 % of instructors use detectors without a policy (Prothero 2024).

# Guiding principles
Avoid sole reliance on AI detectors for high‑stakes decisions involving ELLs (integrity violations, admissions, grades).
Mandatory human review and appeal procedures when ELLs are implicated.
Transparency: inform students when detectors are used, disclose error rates and known biases.
Civil‑rights protections: prohibit denial of enrollment, visa revocation, or punitive measures based solely on detector findings.
Holistic, culturally responsive assessment rather than punitive responses.

# Power - Interest Stakeholder Matrix

| Stakeholder               | Power | Interest | Quadrant                | Action Items |
|---------------------------|-------|----------|------------------------|--------------|
| Provost / Academic Integrity Office | High | High | Manage Closely | • Sponsor steering committee<br>• Approve budget |
| Legal / Compliance Office | High | Medium‑High | Manage Closely | • Review policy language for Title IV compliance |
| IT Services               | High | Medium   | Keep Satisfied | • Provide integration timeline<br>• Allocate API support |
| Faculty Senate / Dept. Chairs | Medium | High | Manage Closely | • Draft department‑level addenda<br>• Host workshops |
| Individual Instructors    | Low   | High     | Keep Informed | • Distribute quick‑start guide<br>• Collect usability feedback |
| ELL / International Students | Low | High | Keep Informed | • Conduct focus groups<br>• Publish plain‑language policy |
| AI‑Detector Vendors       | Medium| Low‑Medium| Monitor | • Request bias‑mitigation documentation |
| State Education Agency    | High  | Low‑Medium| Keep Satisfied | • Submit compliance summary |
| Student Government        | Low‑Medium| High | Keep Informed | • Invite to review meetings |
| General Public / Media    | Low   | Low      | Monitor | • Prepare press kit (on‑demand) |

# Stakeholders
International students and English language learners – consequences can include deportation (Castellanos‑Canales 2025; University of Rochester 2025).
Instructors at higher‑education institutions.
Companies that create AI‑detector algorithms.
Administrative personnel – supervisors who must understand detector impacts and explore solutions.
National, state, and local governments – responsible for training and regulation of AI detectors and “AI humanizers.”
Bias against ELLs may stem from training data or algorithm design; addressing these issues is manageable and can spur broader discussions on algorithmic fairness (Williams 2025). The White House AI Bill of Rights (2022) underscores the privacy and civil‑rights stakes.

# Implementation Timeline for AI‑Detector Policy (ELL Focus)

| Phase | Duration | Main Goal | Decision Point |
|-------|----------|-----------|----------------|
| **0 – Initiation & Governance** | 2 weeks | Secure sponsorship, define scope, assemble steering team | Go/No‑Go to Phase 1 |
| **1 – Discovery & Requirements** | 4 weeks | Gather evidence, map workflows, capture stakeholder needs | Approve Requirements → Phase 2 |
| **2 – Policy Draft & Legal Review** | 3 weeks | Write policy language, embed bias‑mitigation clauses, obtain legal sign‑off | Legal Sign‑off → Phase 3 |
| **3 – Technical Pilot** | 6 weeks (1 semester) | Deploy a limited‑scope detector + human‑review workflow in 2‑3 courses | Pilot Evaluation → Phase 4 |
| **4 – Full‑Scale Roll‑out** | 8 weeks (2 semesters) | Institution‑wide adoption, training, support infrastructure | Roll‑out Review → Phase 5 |
| **5 – Monitoring & Continuous Improvement** | Ongoing (quarterly) | Track metrics, refine policy, update tools | Annual Review (renew or revise) |

# Appendix I – AI usage
1. Grammarly – https://app.grammarly.com/
    - Used throughout the paper to check spelling and grammar.
    - No conversational exchange with the tool.
    - Suggested wording changes and corrected spelling; not all suggestions were accepted.
    - Chosen to ensure consistent word choice across the document.
2. Google summaries
    - Primarily used to find relevant case studies and sources.
    - Some summaries generated by Google searches served as a basis for portions of the written material.
3. EndNote 2025‑1 – https://endnote.com/
    - Created the bibliography.
    - Generated the in‑text citations.
    - Selected because it enforces APA style (including line‑number features) for both citations and bibliography.
4. Lumo AI chatbot (Proton) – https://lumo.proton.me/
    - Evaluated the document and suggested possible corrections (run before final edits).
    - Conversation link: https://lumo.proton.me/u/5/c/d483b174-4cac-41ac-be92-90d25b790426
    - Prompt used: “evaluate the word document based on the rubric.”
    - Full conversation is referenced in Appendix II.
5. Perplexity (Comet Assistant) search engine
    - Used to search for sources and retrieve relevant articles, reports, and policy documents.
6. Writefull – https://www.writefull.com/
    - Word‑processing plugin (free version) used to correct some word choices and improve phrasing.

## Summary
These AI‑enabled tools helped with:
    - Source discovery (Google, Perplexity)
    - Citation management (EndNote)
    - Writing mechanics (Grammarly, Writefull)
    - Content review (Lumo)

While the paper could have been completed without AI, leveraging these tools streamlined research, citation, and editing, making the drafting process faster and more consistent.

# Appendix II – AI Usage – full conversation
(The full Lumo conversation is linked above; a verbatim transcript can be inserted here if needed.)

# Appendix III – Data
Stanford dataset (Myers 2023)

|Sample Size	| Source	| Generated by	| URL |
|------|-----|-----|-----|
| 91	| Chinese TOEFL essays	| Human	|  https://arxiv.org/pdf/2304.02819.pdf |
| 88	| Hewlett Foundation ASAP‑AES dataset	| Human	| https://www.kaggle.com/competitions/asap-aes |

Further code & data: https://github.com/Weixin-Liang/ChatGPT-Detector-Bias/tree/v1.0.0 (Liang et al. 2023a,b).

# Appendix IV – Tables
Table 1. Studies on AI Detection and ESL Writers
Study / Report	Key Findings on ESL / L2 Writers	False‑Positive Rate / Metric
Center for Democracy & Technology brief (based on Stanford study)	AI detectors work almost perfectly on native‑speaker essays; 61 % of non‑native essays flagged; 19 % unanimously flagged; 97 % flagged by at least one detector.	61 % (non‑native)
The Markup (Mathewson 2023)	Replicated Stanford results; ~60 % false positives for ESL writers.	~60 %
Turnitin internal blog	Acknowledges bias toward ELL writers; <1 % overall false positives, but ≥20 % of text flagged when AI content <20 %, especially for ESL writers.	<1 % overall; higher for ESL
Table 2. Comparison of a few AI Detection / Humanizer Tools
Checker	Website	Offers Humanizer?	Comment
JustDone	https://app.justdone.ai/	Yes	Subscription required
GPTZero	https://gptzero.me/	No	Subscription required
Undetectable	https://undetectable.ai/	Yes	Money‑back guarantee if output is flagged
Grammarly	https://app.grammarly.com/	Yes	Subscription required; detected 12 % AI likelihood in test
Copyleaks	https://copyleaks.com/	No	>99 % accuracy claimed; supports 30+ languages
HumanizeAI	https://humanizeai.pro/	Yes	Free, transforms AI text to human‑like
BypassGPT	https://bypassgpt.co/	Limited (up to 2000 chars)	Claims to evade detection
WinstonAI	https://gowinston.ai/	No	Claims 99.98 % accuracy (trial)
BrandWell	https://brandwell.ai/	Yes (2500‑word limit)	First‑stage prototype
OriginalityAI	https://originality.ai/	No	Claims 80 % detection accuracy
Writefull (plugin)	https://writefull.com/	—	Grammar & style aid
Appendix V – Alternate Solutions
Technical Solutions
Pangram Labs AI Detection – aims to reduce false positives for ESL students.

Cost: $5 /student / year.
GPTZero – claims improved bias mitigation; reran Stanford algorithm with better results.

Cost: Free for life (educators).
Assignment‑design toolkits
MIT Sloan – “Designing AI‑Resistant Assignments” (2024) – templates encouraging personal reflection, local data, multiple drafts.
Carnegie Mellon – “Generative AI FAQ for Instructors” (2024) – decision tree for detector use and communication.
Appendix VI – Policy Approaches
Policy Issue	Recommended Practice
Use in high‑stakes cases	Avoid exclusive reliance on AI detectors for ELLs.
Error transparency	Disclose false‑positive rates & known biases.
Human review	Require manual review of flagged ELL work before action.
Civil rights	Prohibit punitive action based solely on AI‑detector results.
Supportive strategies	Use holistic, culturally responsive assessments.
Policymakers are actively monitoring this area; advocacy groups push for clear protections for ELL and international students (see Perplexity search link).
