# AI‑Detection Systems & Non‑Native English Learners: Risks, Evidence, and Policy Recommendations

---

## Introduction  

AI detection systems may incorrectly flag student‑created writing as AI‑generated under certain conditions. Such false positives can harm a student’s academic record and emotional well‑being. The problem is especially acute for **non‑native English speakers** (Najarro, 2023), **neurodivergent students**, and **ESL learners**. Consequently, schools should treat detectors as a **starting point for discussion**, not as definitive proof.

> “Research shows that English‑language‑learner (ESL/E‑Learner) students are significantly more likely to be incorrectly flagged as having used AI‑generated text.”[^1]

### Why non‑native writing is prone to false positives  

- Stylistic variations, unusual phrasing, or unconventional word choices can resemble patterns in AI training data.  
- Most AI models are trained predominantly on native‑speaker corpora, making non‑native writing appear “AI‑like.”  
- ESL essays often exhibit greater lexical and grammatical divergence, which detectors may penalize.

These inaccuracies can trigger **unnecessary academic investigations**, leading to disciplinary actions, loss of credit, and reputational damage. Mitigation strategies include:

1. **Informing ESL students** about detector limitations.  
2. **Encouraging draft/version control** as proof of authorship.  
3. Implementing **institutional safeguards**—manual review, transparent appeals, and heightened educator awareness.

---

## Evidence from Recent Studies  

### 1. Stanford‑based study (Myers 2023; Tian 2023; Woelfel 2023)  

> The study tested seven commercial AI detectors using two datasets: (a) essays written by native‑born U.S. students, and (b) TOEFL essays written by non‑native speakers.  
> - **61 %** of the 91 TOEFL essays were incorrectly flagged as AI‑generated.  
> - All seven detectors unanimously misclassified **18 essays (19 %)**.  
> - At least one detector flagged **97 %** of the TOEFL essays as AI‑generated.  
> The dataset was small, so results may be contested (Tian 2023).

### 2. ResearchGate book chapter (Hirsch 2024)  

The chapter examined false accusations via interviews with **neurodivergent** and **L2 (second‑language)** writers. Findings:

- L2 writers reported **greater anxiety, stigma, and administrative burden** after a false‑positive ID.  
- The authors note that “neurodivergent writers, along with L2 writers, are flagged at higher rates.”

### 3. The Markup investigative article (Mathewson 2023)  

> “AI Detection Tools Falsely Accuse International Students of Cheating” – Tara Garcia Mathewson.  
> - Interviews with faculty and students across several U.S. universities.  
> - Replication of the Stanford experiment confirmed a **61 % false‑positive rate** for non‑native essays.  
> - Real‑world disciplinary cases cited (e.g., a student placed on academic probation after a false flag).

### 4. Survey of Instructor Practices (Prothero 2024)  

- **68 %** of instructors reported using an AI detector on student work **without a formal policy**.  
- Lack of policy correlates with unpredictable outcomes and heightened risk of unfair penalties.

---

## Policy Recommendation  

Institutions should adopt a **comprehensive policy** that includes:

1. **Training for ESL instructors** – delivered via college‑level workshops covering:
   - *Why* and *when* to use AI‑detection tools.  
   - Guidance on **selecting the best tools** (accuracy, bias mitigation, cost).  
   - Baseline sampling, initial review scanning, and proactive student communication.

2. **Manual review requirement** – any detector flag must be followed by a **human reviewer** before any academic‑integrity action.

3. **Transparent appeals process** – clear steps, timelines, and documentation for students to contest detections.

4. **Educator awareness** – regular seminars on detector limitations, bias, and best practices.

5. **Technical safeguards** – consider bias‑reduction tools (e.g., *Pangram Labs AI Detection*; Tian 2023) and, where appropriate, **disable** problematic detector modules (as Vanderbilt University did with Turnitin’s AI detector; Coley 2023).

### Alternative Technical Solutions  

- **Pangram Labs AI Detection** – a bias‑aware detector costing **$5 /student / year** (Jiang et al., 2024).  
- **GPTZero** – claims a technical fix; offered **free for life** to educators (Tian 2023).  

Both can complement policy safeguards but should not replace human oversight.

### Counterpoint  

Jiang et al. (2024) analyzed a larger dataset (<https://github.com/Weixin-Liang/ChatGPT-Detector-Bias/>) and concluded **no systematic bias** against ESL essays. While methodologically robust, this study does **not** address the broader harms of relying solely on detector outputs. Hence, a **policy or behavioral change** remains essential.

---

## Implementation Framework  

| **Goal** | **Action** | **Responsible Party** | **Timeline** |
|----------|------------|-----------------------|--------------|
| **Instructor Training** | Develop workshop curriculum; schedule sessions | ESL Program Director & Teaching & Learning Center | Semester 1 |
| **Tool Selection** | Evaluate detectors for accuracy, bias, cost; choose primary tool | Academic Integrity Office + IT Services | Month 2 |
| **Policy Draft** | Write policy language; embed human‑review & appeals clauses | Legal Counsel + Academic Integrity Office | Month 3 |
| **Pilot Phase** | Run detector + manual‑review workflow in 2‑3 courses | Pilot Faculty Champions | Months 4‑5 |
| **Full Roll‑out** | Deploy policy campus‑wide; mandatory training for all faculty | Provost Office + Communications | Month 6 onward |
| **Monitoring** | Quarterly KPI dashboard (false‑positive rate, appeal volume) | Monitoring Sub‑Committee (Legal, IT, Faculty, Student Rep) | Ongoing |

---

## Conclusion  

AI‑detectors, in their current form, **disproportionately penalize non‑native English learners**, causing academic, psychological, and immigration‑related harms. A **policy‑driven approach**—combining mandatory human review, transparent appeals, educator training, and bias‑aware tooling—offers the most balanced solution to protect student rights while preserving academic integrity.

---

## Appendices  

### Appendix I – AI Usage  

The following AI tools were used in the creation of this document:

1. **Grammarly** (<https://app.grammarly.com/>)  
   - Checked spelling and grammar throughout.  
   - Suggested wording changes; not all were accepted.  

2. **Google Summaries**  
   - Used to locate relevant case studies and sources.  

3. **Lumo (Proton)** (<https://lumo.proton.me/>) – *Web‑search mode*  
   - Prompts used:  
     1. *What are the consequences of having one's writing incorrectly labelled as AI‑generated?*  
     2. *Are ESL students more likely to be incorrectly found to have used AI? Please give all sources.*  
     3. *What are some case studies dealing specifically with this issue?*  
     4. *Is there a study regarding the negative impact of teachers voluntarily using AI detectors?*  

4. **EndNote 2025** (<https://endnote.com/>)  
   - Managed bibliography and in‑text citations.  

> *The various AI tools were used to find different sources and case studies (Google summaries and searches) to support the content I already had and the various ideas I put forth (Lumo explanations and web searches). These tools also aided in annotating this document (EndNote) and checking spelling and grammar throughout the document (Grammarly). Although this paper could have been finished without the use of any AI, using AI made it easier to locate and identify the resources and relevant case studies I could have eventually located. The error checking by Grammarly and MS Word built‑in checker made writing much simpler.*  

> *During the writing of this paper, I have expressly looked for and found instances where the AI in use either did not understand what was being said in the document, incorrectly tried to correct it, or both.*

---

### Appendix II – Tables  

#### Table 1. Studies on AI Detection and ESL Writers  

| **Study / Report** | **Key Findings on ESL / L2 Writers** | **False‑Positive Rate / Metric** |
|--------------------|---------------------------------------|-----------------------------------|
| Center for Democracy & Technology brief (based on Stanford study) – “Disproportionate Effects of Generative AI Detectors on English Learners” | AI detectors that worked almost perfectly on native‑speaker essays falsely flagged a majority of TOEFL essays. | **61 %** of non‑native essays flagged; **19 %** unanimously; **97 %** flagged by at least one detector. |
| *The Markup* (Mathewson, 2023) | Replicated Stanford study; ESL writers disproportionately likely to be flagged. | Same figures (~60 % false positives); disciplinary cases reported. |
| Turnitin blog (internal research) | Acknowledges bias toward ELL writers; < 1 % overall false positives when ≥ 20 % of text is AI, but higher incidence with low‑AI content, especially for ESL writers. | No precise overall % for ESL, but bias confirmed. |

#### Table 2. Comparison of AI Detection Tools  

| **Checker** | **Website** | **Offers Humanizer?** | **% Likely AI (Before Humanizing)** | **% Likely AI (After Humanizing)** |
|------------|-------------|-----------------------|--------------------------------------|-------------------------------------|
| JustDone | <https://app.justdone.ai> | Yes | 14 % | 0 % |
| GPTZero | <https://gptzero.me/> | No | 6 % (2 % AI + 4 % mixed) | 1 % |
| Undetectable | <https://undetectable.ai/> | Yes | 1 % | 1 % |
| Grammarly | <https://app.grammarly.com/> | Yes | 15 % | 8 % |
| Copyleaks | <https://copyleaks.com/> | No | 59.7 % (first 11 k characters) | — |
| HumanizeAI | <https://www.humanizeai.pro/> | Yes | N/A | N/A |
| BypassGPT | <https://bypassgpt.co/> | Yes | N/A | N/A |

---

### Appendix III – Alternate Solutions  

**Technical Solutions**

1. **Bias‑aware detection (Pangram Labs)** – Develop a method for identifying AI‑generated text while minimizing false positives for ESL students.  
   - *Cost:* **$5 /student / year** (Jiang et al., 2024).  

2. **GPTZero** – Claims a technical fix; reran the Stanford algorithm with improved results.  
   - *Cost:* **Free for life** for educators (Tian 2023).  

**Assignment‑design toolkits (already available)**  

- **MIT Sloan – Designing AI‑Resistant Assignments** (2024) – Templates for prompts that require personal reflection, local data, or iterative drafts, making pure AI generation impractical. <https://mitsloanedtech.mit.edu/ai/teach/ai-detectors-dont-work/>  

- **Carnegie Mellon – Generative AI FAQ for Instructors** (2024) – Decision tree on when to use a detector, when to rely on draft histories, and how to communicate expectations. <https://www.cmu.edu/teaching/technology/aitools/index.html>  

---

### Bibliography  

1. **AI Detectors Don’t Work. Here’s What to Do Instead.** (2024). *MIT Sloan Teaching & Learning Technologies*.  
2. **Coley, M.** (2023). *Guidance on AI Detection and Why We’re Disabling Turnitin’s AI Detector*. Retrieved 09/09 from https://www.vanderbilt.edu/brightspace/2023/08/16/guidance-on-ai-detection-and-why-were-disabling-turnitins-ai-detector/  
3. **Hirsch, A.** (2024). *AI detectors: An ethical minefield* – Center for Innovative Teaching and Learning.  
4. **Jiang, Y., Hao, J., Fauss, M., & Li, C.** (2024). Detecting ChatGPT‑generated essays in a large‑scale writing assessment: Is there a bias against non‑native English speakers? *Computers & Education*, 217, 105070. https://doi.org/10.1016/j.compedu.2024.105070  
5. **justdone.** (2025). *Justdone*.  
6. **Mathewson, T. G.** (2023, August 14). *AI Detection Tools Falsely Accuse International Students of Cheating – The Markup*.  
7. **Myers, A.** (2023). *AI‑Detectors Biased Against Non‑Native English Writers* – Stanford HAI. Retrieved 09/09 from https://hai.stanford.edu/news/ai-detectors-biased-against-non-native-english-writers  
8. **Najarro, I.** (2023, October 6). *What Teachers Should Know Before Using AI With English Learners*. *Education Week*.  
9. **Pangram Labs AI Detection**.  
10. **Prothero, A.** (2024). *More Teachers Are Using AI‑Detection Tools. Here’s Why That Might Be a Problem*. *Education Week*.  
11. **Technology, U.S. Office of Education.** (2023). *Artificial Intelligence and the Future of Teaching and Learning: Insights and Recommendations*. U.S. Department of Education, Office of Educational Technology.  
12. **Tian, E.** (2023, October 25). *ESL Bias in AI Detection is an Outdated Narrative*. Retrieved 09/09 from https://gptzero.me/news/esl-and-ai-detection/  
13. **University, Carnegie Mellon.** (2024). *Generative AI Tools FAQ – Eberly Center – Carnegie Mellon University*.  
14. **Woelfel, K.** (2023). *Brief – Late Applications: Disproportionate Effects of Generative AI‑Detectors on English Learners*. Center for Democracy and Technology.  

---

[^1]: See **Table 1** for the underlying study details.  

---  

*End of document.*

3 files
